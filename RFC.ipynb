{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing CSV files\n",
    "folder_path = \"data/\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns=['author', 'date', 'post'], inplace=True)\n",
    "combined_df = combined_df[combined_df['subreddit'].isin(['addiction', 'adhd', 'alcoholism', 'anxiety', 'autism', 'bpd', 'depression', 'lonely', 'ptsd', 'schizophrenia', 'suicidewatch'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = combined_df.drop('subreddit', axis=1)  # Features\n",
    "y = combined_df['subreddit']  # Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# Step 2: Standard Scaling and Min-Max Scaling for numerical features\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_final = standard_scaler.fit_transform(X)\n",
    "\n",
    "# pca = PCA(n_components=100)  # You can adjust the number of components as needed\n",
    "# X_pca = pca.fit_transform(X_final)\n",
    "# X_final = minmax_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final  , y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Encode the categorical target variable (y_train) using OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Step 2: Flatten the encoded labels\n",
    "y_train_encoded = y_train_encoded.argmax(axis=1)\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1)).argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-30 09:45:02,423] A new study created in memory with name: no-name-304cf812-c4c1-4138-9210-3963e10614d0\n",
      "[I 2023-10-30 09:55:12,393] Trial 0 finished with value: 0.6536448598130841 and parameters: {'n_estimators': 152}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:04:02,760] Trial 1 finished with value: 0.6536181575433911 and parameters: {'n_estimators': 158}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:08:20,622] Trial 2 finished with value: 0.6528704939919893 and parameters: {'n_estimators': 108}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:11:30,963] Trial 3 finished with value: 0.6504939919893191 and parameters: {'n_estimators': 80}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:17:23,451] Trial 4 finished with value: 0.6532843791722296 and parameters: {'n_estimators': 149}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:20:44,628] Trial 5 finished with value: 0.6510146862483311 and parameters: {'n_estimators': 85}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:23:03,259] Trial 6 finished with value: 0.646675567423231 and parameters: {'n_estimators': 59}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:25:40,031] Trial 7 finished with value: 0.6486248331108144 and parameters: {'n_estimators': 67}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:28:38,698] Trial 8 finished with value: 0.649305740987984 and parameters: {'n_estimators': 76}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:31:01,682] Trial 9 finished with value: 0.6476368491321762 and parameters: {'n_estimators': 61}. Best is trial 0 with value: 0.6536448598130841.\n",
      "[I 2023-10-30 10:38:48,079] Trial 10 finished with value: 0.6547930574098798 and parameters: {'n_estimators': 199}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 10:46:49,940] Trial 11 finished with value: 0.654712950600801 and parameters: {'n_estimators': 200}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 10:54:13,777] Trial 12 finished with value: 0.654539385847797 and parameters: {'n_estimators': 189}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:01:36,102] Trial 13 finished with value: 0.654539385847797 and parameters: {'n_estimators': 189}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:08:28,180] Trial 14 finished with value: 0.6542323097463284 and parameters: {'n_estimators': 176}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:13:16,785] Trial 15 finished with value: 0.6535514018691588 and parameters: {'n_estimators': 123}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:21:05,188] Trial 16 finished with value: 0.654712950600801 and parameters: {'n_estimators': 200}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:27:40,428] Trial 17 finished with value: 0.654018691588785 and parameters: {'n_estimators': 169}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:32:55,941] Trial 18 finished with value: 0.653324432576769 and parameters: {'n_estimators': 135}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:40:43,161] Trial 19 finished with value: 0.654712950600801 and parameters: {'n_estimators': 200}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:47:36,822] Trial 20 finished with value: 0.6542857142857142 and parameters: {'n_estimators': 177}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 11:55:14,733] Trial 21 finished with value: 0.654739652870494 and parameters: {'n_estimators': 196}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 12:02:29,990] Trial 22 finished with value: 0.6544459279038718 and parameters: {'n_estimators': 186}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 12:08:55,675] Trial 23 finished with value: 0.6539118825100133 and parameters: {'n_estimators': 165}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 12:16:13,237] Trial 24 finished with value: 0.6543524699599466 and parameters: {'n_estimators': 187}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 12:24:08,619] Trial 25 finished with value: 0.654712950600801 and parameters: {'n_estimators': 200}. Best is trial 10 with value: 0.6547930574098798.\n",
      "[I 2023-10-30 12:29:30,746] Trial 26 finished with value: 0.653297730307076 and parameters: {'n_estimators': 136}. Best is trial 10 with value: 0.6547930574098798.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    # max_depth = trial.suggest_int(\"max_depth\", 19, 40)\n",
    "    # min_samples_split = trial.suggest_float(\"min_samples_split\", 0.1, 1.0)\n",
    "    # min_samples_leaf = trial.suggest_float(\"min_samples_leaf\", 0.1, 0.5)\n",
    "\n",
    "    # Initialize the Random Forest Classifier with suggested hyperparameters\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=None,\n",
    "        criterion='entropy',\n",
    "        # min_samples_split=min_samples_split,\n",
    "        # min_samples_leaf=min_samples_leaf,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create an Optuna study for optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize the objective function\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials\n",
    "\n",
    "# Get the best hyperparameters from the study\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Initialize the Random Forest Classifier with the best hyperparameters\n",
    "best_clf = RandomForestClassifier(\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    # min_samples_split=best_params[\"min_samples_split\"],\n",
    "    # min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.55\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60      1577\n",
      "           1       0.84      0.64      0.73      9182\n",
      "           2       0.48      0.83      0.61      1254\n",
      "           3       0.75      0.72      0.74     11419\n",
      "           4       0.17      0.65      0.27      1754\n",
      "           5       0.79      0.49      0.60      4899\n",
      "           6       0.75      0.34      0.47     23472\n",
      "           7       0.31      0.71      0.43      4724\n",
      "           8       0.60      0.61      0.61      1766\n",
      "           9       0.20      0.33      0.25      1788\n",
      "          10       0.52      0.67      0.58     13065\n",
      "\n",
      "    accuracy                           0.55     74900\n",
      "   macro avg       0.54      0.61      0.54     74900\n",
      "weighted avg       0.66      0.55      0.57     74900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the best classifier to the entire training dataset\n",
    "best_clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_test_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generate a classification report on the test data\n",
    "class_report = classification_report(y_test_encoded, y_test_pred, zero_division=0)\n",
    "print(\"Test Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Initializing the Random Forest classifier\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced_subsample', verbose=2)\n",
    "\n",
    "# # Fitting the classifier to the training data\n",
    "# rf_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "# # Making predictions on the test data\n",
    "# predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# # Calculating accuracy\n",
    "# accuracy = accuracy_score(y_test_encoded, predictions)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Generating a classification report\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test_encoded, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
