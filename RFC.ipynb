{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing CSV files\n",
    "folder_path = \"data/\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns=['author', 'date', 'post'], inplace=True)\n",
    "combined_df = combined_df[combined_df['subreddit'].isin(['addiction', 'adhd', 'alcoholism', 'anxiety', 'autism', 'bpd', 'depression', 'lonely', 'ptsd', 'schizophrenia', 'suicidewatch'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = combined_df.drop('subreddit', axis=1)  # Features\n",
    "y = combined_df['subreddit']  # Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# Step 2: Standard Scaling and Min-Max Scaling for numerical features\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_final = standard_scaler.fit_transform(X)\n",
    "\n",
    "# pca = PCA(n_components=100)  # You can adjust the number of components as needed\n",
    "# X_pca = pca.fit_transform(X_final)\n",
    "# X_final = minmax_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final  , y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Encode the categorical target variable (y_train) using OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Step 2: Flatten the encoded labels\n",
    "y_train_encoded = y_train_encoded.argmax(axis=1)\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1)).argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2023-10-29 16:47:16,353] A new study created in memory with name: no-name-ffe32c63-058e-42ae-9b90-46db08715184\n",
      "[I 2023-10-29 16:52:00,822] Trial 0 finished with value: 0.6538718291054739 and parameters: {'n_estimators': 115, 'max_depth': 33}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 16:54:41,756] Trial 1 finished with value: 0.6462616822429906 and parameters: {'n_estimators': 64, 'max_depth': 34}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 16:57:15,708] Trial 2 finished with value: 0.6404272363150868 and parameters: {'n_estimators': 68, 'max_depth': 24}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 16:59:47,694] Trial 3 finished with value: 0.6449532710280373 and parameters: {'n_estimators': 62, 'max_depth': 38}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 17:02:33,532] Trial 4 finished with value: 0.6507610146862484 and parameters: {'n_estimators': 74, 'max_depth': 28}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 17:05:01,112] Trial 5 finished with value: 0.6296795727636849 and parameters: {'n_estimators': 74, 'max_depth': 22}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 17:07:22,695] Trial 6 finished with value: 0.6449532710280373 and parameters: {'n_estimators': 66, 'max_depth': 25}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 17:11:06,543] Trial 7 finished with value: 0.652283044058745 and parameters: {'n_estimators': 96, 'max_depth': 37}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 17:14:42,241] Trial 8 finished with value: 0.6397596795727637 and parameters: {'n_estimators': 106, 'max_depth': 23}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 17:18:46,789] Trial 9 finished with value: 0.6534445927903871 and parameters: {'n_estimators': 107, 'max_depth': 31}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 17:23:09,718] Trial 10 finished with value: 0.6009078771695594 and parameters: {'n_estimators': 146, 'max_depth': 19}. Best is trial 0 with value: 0.6538718291054739.\n",
      "[I 2023-10-29 17:27:49,568] Trial 11 finished with value: 0.6546194926568758 and parameters: {'n_estimators': 119, 'max_depth': 32}. Best is trial 11 with value: 0.6546194926568758.\n",
      "[I 2023-10-29 17:32:52,720] Trial 12 finished with value: 0.6549265687583444 and parameters: {'n_estimators': 132, 'max_depth': 31}. Best is trial 12 with value: 0.6549265687583444.\n",
      "[I 2023-10-29 17:38:11,124] Trial 13 finished with value: 0.6549532710280374 and parameters: {'n_estimators': 135, 'max_depth': 30}. Best is trial 13 with value: 0.6549532710280374.\n",
      "[I 2023-10-29 17:43:44,044] Trial 14 finished with value: 0.6560080106809079 and parameters: {'n_estimators': 145, 'max_depth': 28}. Best is trial 14 with value: 0.6560080106809079.\n",
      "[I 2023-10-29 17:49:17,328] Trial 15 finished with value: 0.6555273698264352 and parameters: {'n_estimators': 143, 'max_depth': 28}. Best is trial 14 with value: 0.6560080106809079.\n",
      "[I 2023-10-29 17:55:04,801] Trial 16 finished with value: 0.6538584779706275 and parameters: {'n_estimators': 149, 'max_depth': 27}. Best is trial 14 with value: 0.6560080106809079.\n",
      "[I 2023-10-29 17:58:27,873] Trial 17 finished with value: 0.6513484646194927 and parameters: {'n_estimators': 90, 'max_depth': 27}. Best is trial 14 with value: 0.6560080106809079.\n",
      "[I 2023-10-29 18:03:52,913] Trial 18 finished with value: 0.6537650200267022 and parameters: {'n_estimators': 132, 'max_depth': 36}. Best is trial 14 with value: 0.6560080106809079.\n",
      "[I 2023-10-29 18:09:37,861] Trial 19 finished with value: 0.6539252336448598 and parameters: {'n_estimators': 141, 'max_depth': 40}. Best is trial 14 with value: 0.6560080106809079.\n",
      "[I 2023-10-29 18:13:48,354] Trial 20 finished with value: 0.6219626168224299 and parameters: {'n_estimators': 123, 'max_depth': 21}. Best is trial 14 with value: 0.6560080106809079.\n",
      "[I 2023-10-29 18:19:21,879] Trial 21 finished with value: 0.6567957276368491 and parameters: {'n_estimators': 136, 'max_depth': 29}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 18:25:53,687] Trial 22 finished with value: 0.6566355140186916 and parameters: {'n_estimators': 150, 'max_depth': 29}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 18:30:46,795] Trial 23 finished with value: 0.6526835781041389 and parameters: {'n_estimators': 128, 'max_depth': 26}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 18:36:38,642] Trial 24 finished with value: 0.6565287049399199 and parameters: {'n_estimators': 139, 'max_depth': 29}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 18:38:43,661] Trial 25 finished with value: 0.6464886515353805 and parameters: {'n_estimators': 51, 'max_depth': 29}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 18:44:36,853] Trial 26 finished with value: 0.6540453938584779 and parameters: {'n_estimators': 137, 'max_depth': 34}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 18:51:08,363] Trial 27 finished with value: 0.6552336448598131 and parameters: {'n_estimators': 150, 'max_depth': 30}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 18:55:55,584] Trial 28 finished with value: 0.6500801068090788 and parameters: {'n_estimators': 125, 'max_depth': 25}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 19:00:41,300] Trial 29 finished with value: 0.6526969292389854 and parameters: {'n_estimators': 113, 'max_depth': 34}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 19:05:39,647] Trial 30 finished with value: 0.6541522029372496 and parameters: {'n_estimators': 116, 'max_depth': 32}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 19:11:31,688] Trial 31 finished with value: 0.6559279038718291 and parameters: {'n_estimators': 140, 'max_depth': 28}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 19:17:55,448] Trial 32 finished with value: 0.6566355140186916 and parameters: {'n_estimators': 150, 'max_depth': 29}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 19:23:28,951] Trial 33 finished with value: 0.654712950600801 and parameters: {'n_estimators': 136, 'max_depth': 30}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 19:30:12,648] Trial 34 finished with value: 0.6562750333778371 and parameters: {'n_estimators': 149, 'max_depth': 32}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 19:35:56,965] Trial 35 finished with value: 0.6527903871829105 and parameters: {'n_estimators': 130, 'max_depth': 26}. Best is trial 21 with value: 0.6567957276368491.\n",
      "[I 2023-10-29 19:42:12,030] Trial 36 finished with value: 0.6569158878504673 and parameters: {'n_estimators': 141, 'max_depth': 29}. Best is trial 36 with value: 0.6569158878504673.\n",
      "[I 2023-10-29 19:49:40,973] Trial 37 finished with value: 0.6552202937249666 and parameters: {'n_estimators': 144, 'max_depth': 33}. Best is trial 36 with value: 0.6569158878504673.\n",
      "[I 2023-10-29 19:53:35,284] Trial 38 finished with value: 0.6427770360480641 and parameters: {'n_estimators': 84, 'max_depth': 24}. Best is trial 36 with value: 0.6569158878504673.\n",
      "[I 2023-10-29 20:00:00,164] Trial 39 finished with value: 0.6538584779706275 and parameters: {'n_estimators': 149, 'max_depth': 27}. Best is trial 36 with value: 0.6569158878504673.\n",
      "[I 2023-10-29 20:05:17,799] Trial 40 finished with value: 0.6526969292389854 and parameters: {'n_estimators': 123, 'max_depth': 35}. Best is trial 36 with value: 0.6569158878504673.\n",
      "[I 2023-10-29 20:13:08,909] Trial 41 finished with value: 0.6553404539385848 and parameters: {'n_estimators': 139, 'max_depth': 31}. Best is trial 36 with value: 0.6569158878504673.\n",
      "[I 2023-10-29 20:19:41,539] Trial 42 finished with value: 0.656822429906542 and parameters: {'n_estimators': 142, 'max_depth': 29}. Best is trial 36 with value: 0.6569158878504673.\n",
      "[I 2023-10-29 20:25:02,766] Trial 43 finished with value: 0.6569425901201602 and parameters: {'n_estimators': 144, 'max_depth': 29}. Best is trial 43 with value: 0.6569425901201602.\n",
      "[I 2023-10-29 20:30:04,277] Trial 44 finished with value: 0.6551001335113484 and parameters: {'n_estimators': 133, 'max_depth': 31}. Best is trial 43 with value: 0.6569425901201602.\n",
      "[I 2023-10-29 20:35:16,299] Trial 45 finished with value: 0.6524699599465955 and parameters: {'n_estimators': 144, 'max_depth': 26}. Best is trial 43 with value: 0.6569425901201602.\n",
      "[W 2023-10-29 20:39:21,778] Trial 46 failed with parameters: {'n_estimators': 109, 'max_depth': 29} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yq/4r6p5rr91jl0sq8dt61vf_f00000gn/T/ipykernel_20144/3850566810.py\", line 32, in objective\n",
      "    y_test_pred = clf.predict(X_test)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py\", line 823, in predict\n",
      "    proba = self.predict_proba(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py\", line 876, in predict_proba\n",
      "    Parallel(n_jobs=n_jobs, verbose=self.verbose, require=\"sharedmem\")(\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py\", line 647, in _accumulate_prediction\n",
      "    prediction = predict(X, check_input=False)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 993, in predict_proba\n",
      "    proba = self.tree_.predict(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-29 20:39:21,812] Trial 46 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Optimize the objective function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)  \u001b[39m# You can adjust the number of trials\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Get the best hyperparameters from the study\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train_encoded)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Make predictions on the validation data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m y_test_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Calculate accuracy\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/RFC.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test_encoded, y_test_pred)\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:876\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    871\u001b[0m all_proba \u001b[39m=\u001b[39m [\n\u001b[1;32m    872\u001b[0m     np\u001b[39m.\u001b[39mzeros((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], j), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    873\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39matleast_1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[1;32m    874\u001b[0m ]\n\u001b[1;32m    875\u001b[0m lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mLock()\n\u001b[0;32m--> 876\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[1;32m    877\u001b[0m     delayed(_accumulate_prediction)(e\u001b[39m.\u001b[39;49mpredict_proba, X, all_proba, lock)\n\u001b[1;32m    878\u001b[0m     \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[1;32m    879\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mfor\u001b[39;00m proba \u001b[39min\u001b[39;00m all_proba:\n\u001b[1;32m    882\u001b[0m     proba \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_)\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:647\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[1;32m    641\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m \u001b[39m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[39m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     prediction \u001b[39m=\u001b[39m predict(X, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[39mwith\u001b[39;00m lock:\n\u001b[1;32m    649\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/tree/_classes.py:993\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    991\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    992\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m--> 993\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m    995\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    996\u001b[0m     proba \u001b[39m=\u001b[39m proba[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 150)\n",
    "    # max_depth = trial.suggest_int(\"max_depth\", 19, 40)\n",
    "    # min_samples_split = trial.suggest_float(\"min_samples_split\", 0.1, 1.0)\n",
    "    # min_samples_leaf = trial.suggest_float(\"min_samples_leaf\", 0.1, 0.5)\n",
    "\n",
    "    # Initialize the Random Forest Classifier with suggested hyperparameters\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=None,\n",
    "        criterion='entropy',\n",
    "        # min_samples_split=min_samples_split,\n",
    "        # min_samples_leaf=min_samples_leaf,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Create an Optuna study for optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize the objective function\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials\n",
    "\n",
    "# Get the best hyperparameters from the study\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Initialize the Random Forest Classifier with the best hyperparameters\n",
    "best_clf = RandomForestClassifier(\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    # min_samples_split=best_params[\"min_samples_split\"],\n",
    "    # min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.55\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60      1577\n",
      "           1       0.84      0.64      0.73      9182\n",
      "           2       0.48      0.83      0.61      1254\n",
      "           3       0.75      0.72      0.74     11419\n",
      "           4       0.17      0.65      0.27      1754\n",
      "           5       0.79      0.49      0.60      4899\n",
      "           6       0.75      0.34      0.47     23472\n",
      "           7       0.31      0.71      0.43      4724\n",
      "           8       0.60      0.61      0.61      1766\n",
      "           9       0.20      0.33      0.25      1788\n",
      "          10       0.52      0.67      0.58     13065\n",
      "\n",
      "    accuracy                           0.55     74900\n",
      "   macro avg       0.54      0.61      0.54     74900\n",
      "weighted avg       0.66      0.55      0.57     74900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit the best classifier to the entire training dataset\n",
    "best_clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_test_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Generate a classification report on the test data\n",
    "class_report = classification_report(y_test_encoded, y_test_pred, zero_division=0)\n",
    "print(\"Test Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Initializing the Random Forest classifier\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced_subsample', verbose=2)\n",
    "\n",
    "# # Fitting the classifier to the training data\n",
    "# rf_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "# # Making predictions on the test data\n",
    "# predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# # Calculating accuracy\n",
    "# accuracy = accuracy_score(y_test_encoded, predictions)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Generating a classification report\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test_encoded, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
