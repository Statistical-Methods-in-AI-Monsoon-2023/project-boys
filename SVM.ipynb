{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing CSV files\n",
    "folder_path = \"data/\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Read each CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns=['author', 'date', 'post'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the combined_df, create a new dataframe in which the 'subreddit' column has only the values 'addiction', 'adhd', 'alcoholism', 'anxiety', 'autism', 'bpd', 'depression', 'lonely', 'ptsd', 'schizophrenia', 'suicidewatch'. Name this new dataframe as 'new_df'\n",
    "combined_df = combined_df[combined_df['subreddit'].isin(['addiction', 'adhd', 'alcoholism', 'anxiety', 'autism', 'bpd', 'depression', 'lonely', 'ptsd', 'schizophrenia', 'suicidewatch'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>flesch_kincaid_grade_level</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gulpease_index</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>lix</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>wiener_sachtextformel</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_wish</th>\n",
       "      <th>tfidf_without</th>\n",
       "      <th>tfidf_wonder</th>\n",
       "      <th>tfidf_work</th>\n",
       "      <th>tfidf_worri</th>\n",
       "      <th>tfidf_wors</th>\n",
       "      <th>tfidf_would</th>\n",
       "      <th>tfidf_wrong</th>\n",
       "      <th>tfidf_x200b</th>\n",
       "      <th>tfidf_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31382</th>\n",
       "      <td>adhd</td>\n",
       "      <td>5.400816</td>\n",
       "      <td>6.505840</td>\n",
       "      <td>5.555245</td>\n",
       "      <td>81.416541</td>\n",
       "      <td>68.047619</td>\n",
       "      <td>9.145306</td>\n",
       "      <td>31.706803</td>\n",
       "      <td>9.387100</td>\n",
       "      <td>2.832296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31383</th>\n",
       "      <td>adhd</td>\n",
       "      <td>2.980698</td>\n",
       "      <td>5.751419</td>\n",
       "      <td>4.789892</td>\n",
       "      <td>76.862769</td>\n",
       "      <td>79.896552</td>\n",
       "      <td>8.314655</td>\n",
       "      <td>27.683190</td>\n",
       "      <td>9.017664</td>\n",
       "      <td>2.933491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31384</th>\n",
       "      <td>adhd</td>\n",
       "      <td>5.136889</td>\n",
       "      <td>6.746474</td>\n",
       "      <td>6.981667</td>\n",
       "      <td>69.052500</td>\n",
       "      <td>69.148148</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>34.240741</td>\n",
       "      <td>10.793553</td>\n",
       "      <td>4.375385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31385</th>\n",
       "      <td>adhd</td>\n",
       "      <td>2.841137</td>\n",
       "      <td>5.750767</td>\n",
       "      <td>4.597740</td>\n",
       "      <td>76.904579</td>\n",
       "      <td>82.383459</td>\n",
       "      <td>8.137030</td>\n",
       "      <td>27.109492</td>\n",
       "      <td>8.841846</td>\n",
       "      <td>2.895752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>adhd</td>\n",
       "      <td>5.781923</td>\n",
       "      <td>7.779519</td>\n",
       "      <td>6.423590</td>\n",
       "      <td>72.163077</td>\n",
       "      <td>68.102564</td>\n",
       "      <td>9.302564</td>\n",
       "      <td>37.358974</td>\n",
       "      <td>9.725611</td>\n",
       "      <td>3.969113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit  automated_readability_index  coleman_liau_index  \\\n",
       "31382      adhd                     5.400816            6.505840   \n",
       "31383      adhd                     2.980698            5.751419   \n",
       "31384      adhd                     5.136889            6.746474   \n",
       "31385      adhd                     2.841137            5.750767   \n",
       "31386      adhd                     5.781923            7.779519   \n",
       "\n",
       "       flesch_kincaid_grade_level  flesch_reading_ease  gulpease_index  \\\n",
       "31382                    5.555245            81.416541       68.047619   \n",
       "31383                    4.789892            76.862769       79.896552   \n",
       "31384                    6.981667            69.052500       69.148148   \n",
       "31385                    4.597740            76.904579       82.383459   \n",
       "31386                    6.423590            72.163077       68.102564   \n",
       "\n",
       "       gunning_fog_index        lix  smog_index  wiener_sachtextformel  ...  \\\n",
       "31382           9.145306  31.706803    9.387100               2.832296  ...   \n",
       "31383           8.314655  27.683190    9.017664               2.933491  ...   \n",
       "31384          10.733333  34.240741   10.793553               4.375385  ...   \n",
       "31385           8.137030  27.109492    8.841846               2.895752  ...   \n",
       "31386           9.302564  37.358974    9.725611               3.969113  ...   \n",
       "\n",
       "       tfidf_wish  tfidf_without  tfidf_wonder  tfidf_work  tfidf_worri  \\\n",
       "31382         0.0            0.0           0.0    0.000000     0.000000   \n",
       "31383         0.0            0.0           0.0    0.099106     0.000000   \n",
       "31384         0.0            0.0           0.0    0.000000     0.117894   \n",
       "31385         0.0            0.0           0.0    0.000000     0.000000   \n",
       "31386         0.0            0.0           0.0    0.000000     0.000000   \n",
       "\n",
       "       tfidf_wors  tfidf_would  tfidf_wrong  tfidf_x200b  tfidf_year  \n",
       "31382         0.0     0.095341     0.000000          0.0    0.086429  \n",
       "31383         0.0     0.290114     0.000000          0.0    0.000000  \n",
       "31384         0.0     0.000000     0.126925          0.0    0.000000  \n",
       "31385         0.0     0.303759     0.000000          0.0    0.000000  \n",
       "31386         0.0     0.000000     0.000000          0.0    0.000000  \n",
       "\n",
       "[5 rows x 347 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374499, 347)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "\n",
    "    def __init__(self, C = 1.0):\n",
    "        # C = error term\n",
    "        self.C = C\n",
    "        self.w = 0\n",
    "        self.b = 0\n",
    "\n",
    "    # Hinge Loss Function / Calculation\n",
    "    def hingeloss(self, w, b, x, y):\n",
    "        # Regularizer term\n",
    "        reg = 0.5 * np.sum(w * w)\n",
    "\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "        # Calculate the optimization term for each data point\n",
    "        opt_term = y * (np.dot(w, x.T) + b)\n",
    "\n",
    "\n",
    "        # Calculate the loss for each data point\n",
    "        loss = reg + self.C * np.sum(np.maximum(0, 1 - opt_term))\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):\n",
    "        # The number of features in X\n",
    "        number_of_features = X.shape[1]\n",
    "\n",
    "        # The number of Samples in X\n",
    "        number_of_samples = X.shape[0]\n",
    "\n",
    "        c = self.C\n",
    "\n",
    "        # Creating ids from 0 to number_of_samples - 1\n",
    "        ids = np.arange(number_of_samples)\n",
    "\n",
    "        # Shuffling the samples randomly\n",
    "        np.random.shuffle(ids)\n",
    "\n",
    "        # creating an array of zeros\n",
    "        w = np.zeros((1, number_of_features))\n",
    "        b = 0\n",
    "        losses = []\n",
    "\n",
    "        # Gradient Descent \n",
    "        for i in range(epochs):\n",
    "            # Calculating the Hinge Loss\n",
    "            l = self.hingeloss(w, b, X, Y)\n",
    "\n",
    "            # Appending all losses \n",
    "            losses.append(l)\n",
    "            \n",
    "            # Starting from 0 to the number of samples with batch_size as interval\n",
    "            for batch_initial in range(0, number_of_samples, batch_size):\n",
    "                gradw = 0\n",
    "                gradb = 0\n",
    "\n",
    "                for j in range(batch_initial, batch_initial+ batch_size):\n",
    "                    if j < number_of_samples:\n",
    "                        x = ids[j]\n",
    "                        ti = Y[x] * (np.dot(w, X[x].T) + b)\n",
    "\n",
    "                        if (ti > 1).all():\n",
    "                            gradw += 0\n",
    "                            gradb += 0\n",
    "                        else:\n",
    "                            # Calculating the gradients\n",
    "\n",
    "                            #w.r.t w \n",
    "                            gradw += c * Y[x] * X[x]\n",
    "                            # w.r.t b\n",
    "                            gradb += c * Y[x]\n",
    "\n",
    "                # Updating weights and bias\n",
    "                w = w - learning_rate * w + learning_rate * gradw\n",
    "                b = b + learning_rate * gradb\n",
    "        \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "        return self.w, self.b, losses\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        prediction = np.dot(X, self.w[0]) + self.b # w.x + b\n",
    "        return np.sign(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = combined_df.drop('subreddit', axis=1)  # Features\n",
    "y = combined_df['subreddit']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 346)\n",
      "(20,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yeetusonthefetus/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['lonely', 'autism', 'alcoholism'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yeetusonthefetus/iiit/SMAI/project-boys/SVM.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/SVM.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m svm_model\u001b[39m.\u001b[39mfit(X_train, y_train_encoded)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/SVM.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Step 4: Evaluate the model on the test data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/SVM.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m y_test_encoded \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mtransform(y_test\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/SVM.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m y_pred \u001b[39m=\u001b[39m svm_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yeetusonthefetus/iiit/SMAI/project-boys/SVM.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Calculate accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:1027\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[39m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m warn_on_unknown \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown \u001b[39min\u001b[39;00m {\n\u001b[1;32m   1024\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1025\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfrequent_if_exist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1026\u001b[0m }\n\u001b[0;32m-> 1027\u001b[0m X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(\n\u001b[1;32m   1028\u001b[0m     X,\n\u001b[1;32m   1029\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[1;32m   1030\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1031\u001b[0m     warn_on_unknown\u001b[39m=\u001b[39;49mwarn_on_unknown,\n\u001b[1;32m   1032\u001b[0m )\n\u001b[1;32m   1034\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1036\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_drop_idx_after_grouping \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/iiit/SMAI/project-boys/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:200\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m handle_unknown \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    196\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    197\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound unknown categories \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m in column \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m during transform\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(diff, i)\n\u001b[1;32m    199\u001b[0m     )\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    201\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['lonely', 'autism', 'alcoholism'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Encode the categorical target variable (y_train) using OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Step 2: Flatten the encoded labels\n",
    "y_train_encoded = y_train_encoded.argmax(axis=1)\n",
    "\n",
    "# Step 3: Train the SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, probability=True)  # You can choose different kernel and hyperparameters\n",
    "svm_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Step 4: Evaluate the model on the test data\n",
    "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1)).argmax(axis=1)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report for detailed metrics\n",
    "print(classification_report(y_test_encoded, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
